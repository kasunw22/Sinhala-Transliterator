{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3-sHEQNttaP"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q pydrive google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUGE5g21txgs",
        "outputId": "351d27ee-1c3a-4980-9d90-a022a39819ae"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Authenticate and mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEc64soSg5Y_",
        "outputId": "2586ef5e-d56b-451b-e84f-7d5dc2d24137"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPRlZBlCgiTZ",
        "outputId": "b1c1600e-81ce-40ee-f048-09fda75f2f58"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8knItUBg9Bg",
        "outputId": "018f41b9-1da0-483e-b058-0f2f61d57169"
      },
      "outputs": [],
      "source": [
        "!pip install transformers evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHj84Y974_la"
      },
      "source": [
        "# Test Set 01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK7xSHbWqJkb",
        "outputId": "8389d0d4-bd6f-4625-f780-e9d7d400e8b5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transliteration mapping (from Latin to Sinhala)\n",
        "p = {\n",
        "    # Vowel sounds\n",
        "    'a': 'අ', 'aa': 'ආ', 'A': 'ඇ', 'Aa': 'ඈ', 'i': 'ඉ', 'ie': 'ඊ',\n",
        "    'u': 'උ', 'uu': 'ඌ', 'e': 'එ', 'ea': 'ඒ', 'I': 'ඓ', 'o': 'ඔ',\n",
        "\n",
        "    '-A': 'ැ', '-i': 'ි', '-u': 'ු', '-e': 'ෙ', '-o': 'ො', '-I': 'ෛ',\n",
        "\n",
        "    # Vowel sounds - long\n",
        "    '-aa': 'ා', '-Aa': 'ෑ', '-ie': 'ී', '-ei': 'ේ', '-oe': 'ෝ',\n",
        "    '-uu': 'ූ', '-au': 'ෞ', '\\\\n': 'ං', '\\\\h': 'ඃ', '\\\\N': 'ඞ',\n",
        "\n",
        "    # Consonants - Common\n",
        "    'ka': 'ක', 'ga': 'ග', 'ma': 'ම', 'ya': 'ය', 'ra': 'ර', 'ba': 'බ',\n",
        "    'cha': 'ච', 'ja': 'ජ', 'ta': 'ට', 'la': 'ල', 'Da': 'ඩ', 'wa': 'ව',\n",
        "    'tha': 'ත', 'sa': 'ස', 'da': 'ද', 'ha': 'හ', 'na': 'න', 'pa': 'ප',\n",
        "    'Na': 'ණ', 'La': 'ළ','mi' : 'මි',\n",
        "\n",
        "     # Consonants - Common\n",
        "    'k': 'ක්', 'g': 'ග', 'm': 'ම', 'y': 'ය', 'r': 'ර', 'b': 'බ',\n",
        "    'ch': 'ච', 'j': 'ජ', 't': 'ට', 'l': 'ල', 'da': 'ඩ', 'w': 'ව',\n",
        "    'th': 'ත', 's': 'ස', 'd': 'ද', 'h': 'හ', 'n': 'න', 'p': 'ප',\n",
        "    'N': 'ණ', 'L': 'ළ',\n",
        "\n",
        "    # Consonants - Aspirated\n",
        "    'Ka': 'ඛ', 'Ga': 'ඝ', 'cha': 'ඡ', 'Tha': 'ඨ', 'Dha': 'ඪ',\n",
        "    'Tha': 'ථ', 'dha': 'ධ', 'Pa': 'ඵ', 'bha': 'භ',\n",
        "\n",
        "    # Consonants - Special\n",
        "    'Ba': 'ඹ', 'Sa': 'ශ', 'sha': 'ෂ', 'fa': 'ෆ', 'GNa': 'ඥ',\n",
        "    'KNa': 'ඤ', 'jha': 'ඣ', 'Lu': 'ළු', 'Luu': 'ළූ',\n",
        "\n",
        "    # Special sounds\n",
        "    '-R': 'ර්‍', 'Ya': '්‍ය', 'ra': '්‍ර', '-': '්',\n",
        "\n",
        "    # Handle special cases with ZWJ (Zero Width Joiner)\n",
        "    '-ru': 'ෘ', 'au': 'ඖ',\n",
        "\n",
        "    'ki': 'කි', 'ku': 'කු', 'ke': 'කෙ', 'ko': 'කො',\n",
        "    'kaa': 'කා', 'kAa': 'කෑ', 'kie': 'කී', 'kei': 'කේ',\n",
        "    'koe': 'කෝ', 'kuu': 'කූ', 'kau': 'කෞ',\n",
        "\n",
        "    'gi': 'ගි', 'gu': 'ගු', 'ge': 'ගෙ', 'go': 'ගො',\n",
        "    'gaa': 'ගා', 'gAa': 'ගෑ', 'gie': 'ගී', 'gei': 'ගේ',\n",
        "    'goe': 'ගෝ', 'guu': 'ගූ', 'gau': 'ගෞ',\n",
        "\n",
        "    'mi': 'මි', 'mu': 'මු', 'me': 'මෙ', 'mo': 'මො',\n",
        "    'maa': 'මා', 'mAa': 'මෑ', 'mie': 'මී', 'mei': 'මේ',\n",
        "    'moe': 'මෝ', 'muu': 'මු', 'mau': 'මෞ',\n",
        "\n",
        "    'yi': 'යි', 'yu': 'යු', 'ye': 'යේ', 'yo': 'යෝ',\n",
        "    'yaa': 'යා', 'yAa': 'යෑ', 'yie': 'යී', 'yei': 'යේ',\n",
        "    'yoe': 'යෝ', 'yuu': 'යූ', 'yau': 'යෞ',\n",
        "\n",
        "    'ri': 'රි', 'ru': 'රු', 're': 'රෙ', 'ro': 'රො',\n",
        "    'raa': 'රා', 'rAa': 'රෑ', 'rie': 'රී', 'rei': 'රී',\n",
        "    'roe': 'රෝ', 'ruu': 'රූ', 'rau': 'රෞ',\n",
        "\n",
        "    'bi': 'බි', 'bu': 'බු', 'be': 'බෙ', 'bo': 'බො',\n",
        "    'baa': 'බා', 'bAa': 'බෑ', 'bie': 'බී', 'bei': 'බේ',\n",
        "    'boe': 'බෝ', 'buu': 'බූ', 'bau': 'බෞ',\n",
        "\n",
        "    'ci': 'චි', 'cu': 'චු', 'ce': 'චෙ', 'co': 'චො',\n",
        "    'caa': 'චා', 'cAa': 'චෑ', 'cie': 'චී', 'cei': 'චේ',\n",
        "    'coe': 'චෝ', 'cuu': 'චූ', 'cau': 'චෞ',\n",
        "\n",
        "    'chi': 'චි', 'chu': 'චු', 'che': 'චෙ', 'cho': 'චො',\n",
        "    'chaa': 'චා', 'chAa': 'චෑ', 'chie': 'චී', 'chei': 'චේ',\n",
        "    'choe': 'චෝ', 'chuu': 'චූ', 'chau': 'චෞ',\n",
        "\n",
        "    'ji': 'ජි', 'ju': 'ජු', 'je': 'ජෙ', 'jo': 'ජො',\n",
        "    'jaa': 'ජා', 'jAa': 'ජෑ', 'jie': 'ජී', 'jei': 'ජේ',\n",
        "    'joe': 'ජෝ', 'juu': 'ජූ', 'jau': 'ජෞ',\n",
        "\n",
        "    'ti': 'ටි', 'tu': 'ටු', 'te': 'ටෙ', 'to': 'ටො',\n",
        "    'taa': 'ටා', 'tAa': 'ටෑ', 'tie': 'ටී', 'tei': 'ටේ',\n",
        "    'toe': 'ටෝ', 'tuu': 'ටූ', 'tau': 'ටෞ',\n",
        "\n",
        "    'li': 'ලි', 'lu': 'ළු', 'le': 'ලෙ', 'lo': 'ලො',\n",
        "    'laa': 'ලා', 'lAa': 'ලෑ', 'lie': 'ලී', 'lei': 'ලේ',\n",
        "    'loe': 'ලෝ', 'luu': 'ළු', 'lau': 'ලෞ',\n",
        "\n",
        "    'Di': 'ඩි', 'Du': 'ඩු', 'De': 'ඩෙ', 'Do': 'ඩො',\n",
        "    'Daa': 'ඩා', 'DAa': 'ඩෑ', 'Die': 'ඩී', 'Dei': 'ඩේ',\n",
        "    'Doe': 'ඩෝ', 'Duu': 'ඩූ', 'Dau': 'ඩෞ',\n",
        "\n",
        "    'wi': 'වි', 'wu': 'වු', 'we': 'වේ', 'wo': 'වෝ',\n",
        "    'waa': 'වා', 'wAa': 'වා', 'wie': 'වී', 'wei': 'වී',\n",
        "    'woe': 'වෝ', 'wuu': 'වු', 'wau': 'වෞ',\n",
        "\n",
        "    'thi': 'ති', 'thu': 'තු', 'the': 'තෙ', 'tho': 'තො',\n",
        "    'thaa': 'තා', 'thAa': 'තා', 'thie': 'තී', 'thei': 'තේ',\n",
        "    'thoe': 'තෝ', 'thuu': 'තු', 'thau': 'තෞ',\n",
        "\n",
        "    'si': 'සි', 'su': 'සු', 'se': 'සෙ', 'so': 'සො',\n",
        "    'saa': 'සා', 'sAa': 'සෑ', 'sie': 'සී', 'sei': 'සේ',\n",
        "    'soe': 'සෝ', 'suu': 'සූ', 'sau': 'සෞ',\n",
        "\n",
        "    'di': 'දි', 'du': 'දු', 'de': 'දෙ', 'do': 'දො',\n",
        "    'daa': 'දා', 'dAa': 'දෑ', 'die': 'දී', 'dei': 'දේ',\n",
        "    'doe': 'දෝ', 'duu': 'දූ', 'dau': 'දෞ',\n",
        "\n",
        "    'hi': 'හි', 'hu': 'හු', 'he': 'හෙ', 'ho': 'හො',\n",
        "    'haa': 'හා', 'hAa': 'හා', 'hie': 'හී', 'hei': 'හේ',\n",
        "    'hoe': 'හෝ', 'huu': 'හු', 'hau': 'හෞ',\n",
        "\n",
        "    'ni': 'නි', 'nu': 'නු', 'ne': 'නෙ', 'no': 'නො',\n",
        "    'naa': 'නා', 'nAa': 'නෑ', 'nie': 'නි', 'nei': 'නී',\n",
        "    'noe': 'නෝ', 'nuu': 'නු', 'nau': 'නෞ','n':'න්',\n",
        "\n",
        "    'pi': 'පි', 'pu': 'පු', 'pe': 'පෙ', 'po': 'පො',\n",
        "    'paa': 'පා', 'pAa': 'පෑ', 'pie': 'පී', 'pei': 'පේ',\n",
        "    'poe': 'පෝ', 'puu': 'පූ', 'pau': 'පෞ',\n",
        "\n",
        "    'Na': 'ණි', 'Nu': 'ණු', 'Ne': 'ණෙ', 'No': 'ණො',\n",
        "    'Naa': 'ණා', 'NAa': 'ණෑ', 'Nie': 'ණී', 'Nei': 'ණේ',\n",
        "    'Noe': 'ණෝ', 'Nuu': 'ණූ', 'Nau': 'ණෞ',\n",
        "\n",
        "    'La': 'ළි', 'Lu': 'ළු', 'Le': 'ළෙ', 'Lo': 'ළො',\n",
        "    'Laa': 'ළා', 'LAa': 'ළෑ', 'Lie': 'ළී', 'Lei': 'ළේ',\n",
        "    'Loe': 'ළෝ', 'Luu': 'ළූ', 'Lau': 'ළෞ', 'bha':'භ','bhu':'භු','sh':'ශ'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "# Function to transliterate Latin text to Sinhala\n",
        "def transliterate(word):\n",
        "    word = word.strip()\n",
        "\n",
        "    # Ignore non Latin words (not just Sinhala characters)\n",
        "    is_latin = False\n",
        "    for c in word:\n",
        "        if c.isalpha():  # Latin alphabet check\n",
        "            is_latin = True\n",
        "    if not is_latin:\n",
        "        return word  # return the word as-is if it's not Latin\n",
        "\n",
        "    result = ''\n",
        "    i = 0\n",
        "    while i < len(word):\n",
        "        matched = False\n",
        "        # Try to match the longest possible substring first: 3 letters, 2 letters, then 1 letter\n",
        "        for length in range(3, 0, -1):  # Check 3 letters, then 2, then 1\n",
        "            substring = word[i:i + length].lower()  # Convert to lowercase for case insensitivity\n",
        "            if substring in p:\n",
        "                result += p[substring]\n",
        "                i += length  # Move index forward by the length of the matched substring\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            # If no match is found, simply add the character as-is\n",
        "            result += word[i]\n",
        "            i += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "# Function to process the CSV file\n",
        "def process_csv(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Add a new column for transliterated text\n",
        "    df['Transliterated'] = df['Column1'].apply(transliterate)\n",
        "\n",
        "     # Save the dataframe to a new CSV file\n",
        "    output_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Final_Result/Sinhala-Test-set-1-rulebase.csv'\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"File saved to {output_path}\")\n",
        "\n",
        "    # Print results: input text, expected output, and transliterated output\n",
        "    for index, row in df.iterrows():\n",
        "        print(f\"Input Text: {row['Column1']}\")\n",
        "        print(f\"Expected Output: {row['Column2']}\")\n",
        "        print(f\"Transliterated Output: {row['Transliterated']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Main function to run the program\n",
        "def main():\n",
        "    file_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Sinhala-Test-set-1.csv'\n",
        "    process_csv(file_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUWsk6ZRgObz",
        "outputId": "942a6a50-e422-481e-90cb-26f4b5d77d2b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import evaluate\n",
        "from string import punctuation\n",
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "\n",
        "def compute_metrics(ref_str, pred_str, find_wer=True, find_cer=True, find_bleu=True, do_normalize_text=False):\n",
        "    \"\"\"\n",
        "    Compute evaluation metrics WER, CER, and BLEU for given reference and predicted strings.\n",
        "    \"\"\"\n",
        "    if do_normalize_text:\n",
        "        pred_str = normalizer(pred_str).strip().strip(punctuation).strip()\n",
        "        ref_str = normalizer(ref_str).strip().strip(punctuation).strip()\n",
        "    else:\n",
        "        pred_str = pred_str.strip().strip(punctuation).strip()\n",
        "        ref_str = ref_str.strip().strip(punctuation).strip()\n",
        "\n",
        "    if ref_str and pred_str:\n",
        "        wer = wer_metric.compute(predictions=[pred_str], references=[ref_str]) if find_wer else None\n",
        "        cer = cer_metric.compute(predictions=[pred_str], references=[ref_str]) if find_cer else None\n",
        "        bleu = bleu_metric.compute(predictions=[pred_str], references=[ref_str])[\"bleu\"] if find_bleu else None\n",
        "    else:\n",
        "        wer, cer, bleu = 1.0, 1.0, 0.0  # Default values for empty predictions or references\n",
        "\n",
        "    return wer, cer, bleu\n",
        "\n",
        "# Load evaluation metrics\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "bleu_metric = evaluate.load(\"bleu\")\n",
        "normalizer = BasicTextNormalizer()\n",
        "\n",
        "# Read the dataset\n",
        "file_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Final_Result/Sinhala-Test-set-1-rulebase.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "wer_list, cer_list, bleu_list = [], [], []\n",
        "\n",
        "# Compute metrics for each row\n",
        "for index, row in df.iterrows():\n",
        "    ref = row[\"Column2\"]  # Expected output\n",
        "    pred = row[\"Transliterated\"]  # Rule-based transliteration output\n",
        "    wer, cer, bleu = compute_metrics(ref, pred)\n",
        "    wer_list.append(wer)\n",
        "    cer_list.append(cer)\n",
        "    bleu_list.append(bleu)\n",
        "\n",
        "# Add the metrics to the dataframe\n",
        "df[\"WER\"] = wer_list\n",
        "df[\"CER\"] = cer_list\n",
        "df[\"BLEU\"] = bleu_list\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "output_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Final_Result/Sinhala-Test-set-1-rulebase-with-metrics.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"File with metrics saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA72nz603XMG",
        "outputId": "2e25ffd4-363b-4c8d-e99b-d80b492887d3"
      },
      "outputs": [],
      "source": [
        "# Calculate overall averages\n",
        "average_wer = df[\"WER\"].mean()\n",
        "average_cer = df[\"CER\"].mean()\n",
        "average_bleu = df[\"BLEU\"].mean()\n",
        "\n",
        "# Print the averages\n",
        "print(f\"Overall Averages:\")\n",
        "print(f\"WER: {average_wer:.4f}\")\n",
        "print(f\"CER: {average_cer:.4f}\")\n",
        "print(f\"BLEU: {average_bleu:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8pG-zN-41bw"
      },
      "source": [
        "# Test Set 02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaWWKfrj4is-",
        "outputId": "afc7a432-aaff-40a6-abed-01bb39aa0998"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Transliteration mapping (from Latin to Sinhala)\n",
        "p = {\n",
        "    # Vowel sounds\n",
        "    'a': 'අ', 'aa': 'ආ', 'A': 'ඇ', 'Aa': 'ඈ', 'i': 'ඉ', 'ie': 'ඊ',\n",
        "    'u': 'උ', 'uu': 'ඌ', 'e': 'එ', 'ea': 'ඒ', 'I': 'ඓ', 'o': 'ඔ',\n",
        "\n",
        "    '-A': 'ැ', '-i': 'ි', '-u': 'ු', '-e': 'ෙ', '-o': 'ො', '-I': 'ෛ',\n",
        "\n",
        "    # Vowel sounds - long\n",
        "    '-aa': 'ා', '-Aa': 'ෑ', '-ie': 'ී', '-ei': 'ේ', '-oe': 'ෝ',\n",
        "    '-uu': 'ූ', '-au': 'ෞ', '\\\\n': 'ං', '\\\\h': 'ඃ', '\\\\N': 'ඞ',\n",
        "\n",
        "    # Consonants - Common\n",
        "    'ka': 'ක', 'ga': 'ග', 'ma': 'ම', 'ya': 'ය', 'ra': 'ර', 'ba': 'බ',\n",
        "    'cha': 'ච', 'ja': 'ජ', 'ta': 'ට', 'la': 'ල', 'Da': 'ඩ', 'wa': 'ව',\n",
        "    'tha': 'ත', 'sa': 'ස', 'da': 'ද', 'ha': 'හ', 'na': 'න', 'pa': 'ප',\n",
        "    'Na': 'ණ', 'La': 'ළ','mi' : 'මි',\n",
        "\n",
        "     # Consonants - Common\n",
        "    'k': 'ක්', 'g': 'ග', 'm': 'ම', 'y': 'ය', 'r': 'ර', 'b': 'බ',\n",
        "    'ch': 'ච', 'j': 'ජ', 't': 'ට', 'l': 'ල', 'da': 'ඩ', 'w': 'ව',\n",
        "    'th': 'ත', 's': 'ස', 'd': 'ද', 'h': 'හ', 'n': 'න', 'p': 'ප',\n",
        "    'N': 'ණ', 'L': 'ළ',\n",
        "\n",
        "    # Consonants - Aspirated\n",
        "    'Ka': 'ඛ', 'Ga': 'ඝ', 'cha': 'ඡ', 'Tha': 'ඨ', 'Dha': 'ඪ',\n",
        "    'Tha': 'ථ', 'dha': 'ධ', 'Pa': 'ඵ', 'bha': 'භ',\n",
        "\n",
        "    # Consonants - Special\n",
        "    'Ba': 'ඹ', 'Sa': 'ශ', 'sha': 'ෂ', 'fa': 'ෆ', 'GNa': 'ඥ',\n",
        "    'KNa': 'ඤ', 'jha': 'ඣ', 'Lu': 'ළු', 'Luu': 'ළූ',\n",
        "\n",
        "    # Special sounds\n",
        "    '-R': 'ර්‍', 'Ya': '්‍ය', 'ra': '්‍ර', '-': '්',\n",
        "\n",
        "    # Handle special cases with ZWJ (Zero Width Joiner)\n",
        "    '-ru': 'ෘ', 'au': 'ඖ',\n",
        "\n",
        "    'ki': 'කි', 'ku': 'කු', 'ke': 'කෙ', 'ko': 'කො',\n",
        "    'kaa': 'කා', 'kAa': 'කෑ', 'kie': 'කී', 'kei': 'කේ',\n",
        "    'koe': 'කෝ', 'kuu': 'කූ', 'kau': 'කෞ',\n",
        "\n",
        "    'gi': 'ගි', 'gu': 'ගු', 'ge': 'ගෙ', 'go': 'ගො',\n",
        "    'gaa': 'ගා', 'gAa': 'ගෑ', 'gie': 'ගී', 'gei': 'ගේ',\n",
        "    'goe': 'ගෝ', 'guu': 'ගූ', 'gau': 'ගෞ',\n",
        "\n",
        "    'mi': 'මි', 'mu': 'මු', 'me': 'මෙ', 'mo': 'මො',\n",
        "    'maa': 'මා', 'mAa': 'මෑ', 'mie': 'මී', 'mei': 'මේ',\n",
        "    'moe': 'මෝ', 'muu': 'මු', 'mau': 'මෞ',\n",
        "\n",
        "    'yi': 'යි', 'yu': 'යු', 'ye': 'යේ', 'yo': 'යෝ',\n",
        "    'yaa': 'යා', 'yAa': 'යෑ', 'yie': 'යී', 'yei': 'යේ',\n",
        "    'yoe': 'යෝ', 'yuu': 'යූ', 'yau': 'යෞ',\n",
        "\n",
        "    'ri': 'රි', 'ru': 'රු', 're': 'රෙ', 'ro': 'රො',\n",
        "    'raa': 'රා', 'rAa': 'රෑ', 'rie': 'රී', 'rei': 'රී',\n",
        "    'roe': 'රෝ', 'ruu': 'රූ', 'rau': 'රෞ',\n",
        "\n",
        "    'bi': 'බි', 'bu': 'බු', 'be': 'බෙ', 'bo': 'බො',\n",
        "    'baa': 'බා', 'bAa': 'බෑ', 'bie': 'බී', 'bei': 'බේ',\n",
        "    'boe': 'බෝ', 'buu': 'බූ', 'bau': 'බෞ',\n",
        "\n",
        "    'ci': 'චි', 'cu': 'චු', 'ce': 'චෙ', 'co': 'චො',\n",
        "    'caa': 'චා', 'cAa': 'චෑ', 'cie': 'චී', 'cei': 'චේ',\n",
        "    'coe': 'චෝ', 'cuu': 'චූ', 'cau': 'චෞ',\n",
        "\n",
        "    'chi': 'චි', 'chu': 'චු', 'che': 'චෙ', 'cho': 'චො',\n",
        "    'chaa': 'චා', 'chAa': 'චෑ', 'chie': 'චී', 'chei': 'චේ',\n",
        "    'choe': 'චෝ', 'chuu': 'චූ', 'chau': 'චෞ',\n",
        "\n",
        "    'ji': 'ජි', 'ju': 'ජු', 'je': 'ජෙ', 'jo': 'ජො',\n",
        "    'jaa': 'ජා', 'jAa': 'ජෑ', 'jie': 'ජී', 'jei': 'ජේ',\n",
        "    'joe': 'ජෝ', 'juu': 'ජූ', 'jau': 'ජෞ',\n",
        "\n",
        "    'ti': 'ටි', 'tu': 'ටු', 'te': 'ටෙ', 'to': 'ටො',\n",
        "    'taa': 'ටා', 'tAa': 'ටෑ', 'tie': 'ටී', 'tei': 'ටේ',\n",
        "    'toe': 'ටෝ', 'tuu': 'ටූ', 'tau': 'ටෞ',\n",
        "\n",
        "    'li': 'ලි', 'lu': 'ළු', 'le': 'ලෙ', 'lo': 'ලො',\n",
        "    'laa': 'ලා', 'lAa': 'ලෑ', 'lie': 'ලී', 'lei': 'ලේ',\n",
        "    'loe': 'ලෝ', 'luu': 'ළු', 'lau': 'ලෞ',\n",
        "\n",
        "    'Di': 'ඩි', 'Du': 'ඩු', 'De': 'ඩෙ', 'Do': 'ඩො',\n",
        "    'Daa': 'ඩා', 'DAa': 'ඩෑ', 'Die': 'ඩී', 'Dei': 'ඩේ',\n",
        "    'Doe': 'ඩෝ', 'Duu': 'ඩූ', 'Dau': 'ඩෞ',\n",
        "\n",
        "    'wi': 'වි', 'wu': 'වු', 'we': 'වේ', 'wo': 'වෝ',\n",
        "    'waa': 'වා', 'wAa': 'වා', 'wie': 'වී', 'wei': 'වී',\n",
        "    'woe': 'වෝ', 'wuu': 'වු', 'wau': 'වෞ',\n",
        "\n",
        "    'thi': 'ති', 'thu': 'තු', 'the': 'තෙ', 'tho': 'තො',\n",
        "    'thaa': 'තා', 'thAa': 'තා', 'thie': 'තී', 'thei': 'තේ',\n",
        "    'thoe': 'තෝ', 'thuu': 'තු', 'thau': 'තෞ',\n",
        "\n",
        "    'si': 'සි', 'su': 'සු', 'se': 'සෙ', 'so': 'සො',\n",
        "    'saa': 'සා', 'sAa': 'සෑ', 'sie': 'සී', 'sei': 'සේ',\n",
        "    'soe': 'සෝ', 'suu': 'සූ', 'sau': 'සෞ',\n",
        "\n",
        "    'di': 'දි', 'du': 'දු', 'de': 'දෙ', 'do': 'දො',\n",
        "    'daa': 'දා', 'dAa': 'දෑ', 'die': 'දී', 'dei': 'දේ',\n",
        "    'doe': 'දෝ', 'duu': 'දූ', 'dau': 'දෞ',\n",
        "\n",
        "    'hi': 'හි', 'hu': 'හු', 'he': 'හෙ', 'ho': 'හො',\n",
        "    'haa': 'හා', 'hAa': 'හා', 'hie': 'හී', 'hei': 'හේ',\n",
        "    'hoe': 'හෝ', 'huu': 'හු', 'hau': 'හෞ',\n",
        "\n",
        "    'ni': 'නි', 'nu': 'නු', 'ne': 'නෙ', 'no': 'නො',\n",
        "    'naa': 'නා', 'nAa': 'නෑ', 'nie': 'නි', 'nei': 'නී',\n",
        "    'noe': 'නෝ', 'nuu': 'නු', 'nau': 'නෞ','n':'න්',\n",
        "\n",
        "    'pi': 'පි', 'pu': 'පු', 'pe': 'පෙ', 'po': 'පො',\n",
        "    'paa': 'පා', 'pAa': 'පෑ', 'pie': 'පී', 'pei': 'පේ',\n",
        "    'poe': 'පෝ', 'puu': 'පූ', 'pau': 'පෞ',\n",
        "\n",
        "    'Na': 'ණි', 'Nu': 'ණු', 'Ne': 'ණෙ', 'No': 'ණො',\n",
        "    'Naa': 'ණා', 'NAa': 'ණෑ', 'Nie': 'ණී', 'Nei': 'ණේ',\n",
        "    'Noe': 'ණෝ', 'Nuu': 'ණූ', 'Nau': 'ණෞ',\n",
        "\n",
        "    'La': 'ළි', 'Lu': 'ළු', 'Le': 'ළෙ', 'Lo': 'ළො',\n",
        "    'Laa': 'ළා', 'LAa': 'ළෑ', 'Lie': 'ළී', 'Lei': 'ළේ',\n",
        "    'Loe': 'ළෝ', 'Luu': 'ළූ', 'Lau': 'ළෞ', 'bha':'භ','bhu':'භු','sh':'ශ'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "# Function to transliterate Latin text to Sinhala\n",
        "def transliterate(word):\n",
        "    word = word.strip()\n",
        "\n",
        "    # Ignore non Latin words (not just Sinhala characters)\n",
        "    is_latin = False\n",
        "    for c in word:\n",
        "        if c.isalpha():  # Latin alphabet check\n",
        "            is_latin = True\n",
        "    if not is_latin:\n",
        "        return word  # return the word as-is if it's not Latin\n",
        "\n",
        "    result = ''\n",
        "    i = 0\n",
        "    while i < len(word):\n",
        "        matched = False\n",
        "        # Try to match the longest possible substring first: 3 letters, 2 letters, then 1 letter\n",
        "        for length in range(3, 0, -1):  # Check 3 letters, then 2, then 1\n",
        "            substring = word[i:i + length].lower()  # Convert to lowercase for case insensitivity\n",
        "            if substring in p:\n",
        "                result += p[substring]\n",
        "                i += length  # Move index forward by the length of the matched substring\n",
        "                matched = True\n",
        "                break\n",
        "        if not matched:\n",
        "            # If no match is found, simply add the character as-is\n",
        "            result += word[i]\n",
        "            i += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "# Function to process the CSV file\n",
        "def process_csv(file_path):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Add a new column for transliterated text\n",
        "    df['Transliterated'] = df['Column1'].apply(transliterate)\n",
        "\n",
        "     # Save the dataframe to a new CSV file\n",
        "    output_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Final_Result/Sinhala-Test-set-2-rulebase.csv'\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"File saved to {output_path}\")\n",
        "\n",
        "    # Print results: input text, expected output, and transliterated output\n",
        "    for index, row in df.iterrows():\n",
        "        print(f\"Input Text: {row['Column1']}\")\n",
        "        print(f\"Expected Output: {row['Column2']}\")\n",
        "        print(f\"Transliterated Output: {row['Transliterated']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Main function to run the program\n",
        "def main():\n",
        "    file_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Sinhala-Test-set-2.csv'\n",
        "    process_csv(file_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xke27Vv5JjW",
        "outputId": "2d6703a8-1ab0-4670-9b42-d81905baa3ad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import evaluate\n",
        "from string import punctuation\n",
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "\n",
        "def compute_metrics(ref_str, pred_str, find_wer=True, find_cer=True, find_bleu=True, do_normalize_text=False):\n",
        "    \"\"\"\n",
        "    Compute evaluation metrics WER, CER, and BLEU for given reference and predicted strings.\n",
        "    \"\"\"\n",
        "    if do_normalize_text:\n",
        "        pred_str = normalizer(pred_str).strip().strip(punctuation).strip()\n",
        "        ref_str = normalizer(ref_str).strip().strip(punctuation).strip()\n",
        "    else:\n",
        "        pred_str = pred_str.strip().strip(punctuation).strip()\n",
        "        ref_str = ref_str.strip().strip(punctuation).strip()\n",
        "\n",
        "    if ref_str and pred_str:\n",
        "        wer = wer_metric.compute(predictions=[pred_str], references=[ref_str]) if find_wer else None\n",
        "        cer = cer_metric.compute(predictions=[pred_str], references=[ref_str]) if find_cer else None\n",
        "        bleu = bleu_metric.compute(predictions=[pred_str], references=[ref_str])[\"bleu\"] if find_bleu else None\n",
        "    else:\n",
        "        wer, cer, bleu = 1.0, 1.0, 0.0  # Default values for empty predictions or references\n",
        "\n",
        "    return wer, cer, bleu\n",
        "\n",
        "# Load evaluation metrics\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "bleu_metric = evaluate.load(\"bleu\")\n",
        "normalizer = BasicTextNormalizer()\n",
        "\n",
        "# Read the dataset\n",
        "file_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Final_Result/Sinhala-Test-set-2-rulebase.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "wer_list, cer_list, bleu_list = [], [], []\n",
        "\n",
        "# Compute metrics for each row\n",
        "for index, row in df.iterrows():\n",
        "    ref = row[\"Column2\"]  # Expected output\n",
        "    pred = row[\"Transliterated\"]  # Rule-based transliteration output\n",
        "    wer, cer, bleu = compute_metrics(ref, pred)\n",
        "    wer_list.append(wer)\n",
        "    cer_list.append(cer)\n",
        "    bleu_list.append(bleu)\n",
        "\n",
        "# Add the metrics to the dataframe\n",
        "df[\"WER\"] = wer_list\n",
        "df[\"CER\"] = cer_list\n",
        "df[\"BLEU\"] = bleu_list\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "output_path = '/content/drive/MyDrive/IndoNLPWorkshop_2025/Final_Result/Sinhala-Test-set-2-rulebase-with-metrics.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"File with metrics saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpw8cOeZ6WWV",
        "outputId": "52c3879a-34c5-4cb3-9a82-fd2efb1ffd01"
      },
      "outputs": [],
      "source": [
        "# Calculate overall averages\n",
        "average_wer = df[\"WER\"].mean()\n",
        "average_cer = df[\"CER\"].mean()\n",
        "average_bleu = df[\"BLEU\"].mean()\n",
        "\n",
        "# Print the averages\n",
        "print(f\"Overall Averages:\")\n",
        "print(f\"WER: {average_wer:.4f}\")\n",
        "print(f\"CER: {average_cer:.4f}\")\n",
        "print(f\"BLEU: {average_bleu:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
